上文我们介绍了优惠券下发的现状分析，以及对应的性能优化策略：“优先过滤优化”和“单次改批量优化”。

在本文中，我们会将这两个性能优化策略，一一进行代码落地实现，以及继续介绍并落地其他优化策略，最终将千万量级优惠券下发执行时长，从 30 小时优化至 20 分钟。

接下来，我们看下代码的实现：

```java
public void distributeCoupons1(Coupon coupon, int userGroupID) {

        //插入优惠券，获取优惠券ID
        couponMapper.save(coupon);
        int couponID = coupon.getId();
        //偏移量，用来控制获取VIP用户的位置，类似于SQL语句中的offset，起始位置是0
        long startUserID = 0;
        while (true) {
            //从用户中心批量获取VIP用户的ID集合，每次100条
            List<Long> userIDList = userClient.findVIPBySizeAndOffset(100, startUserID);

            //如果等于空，代表数据没有新的数据返回，则退出
            if (CollectionUtils.isEmpty(userIDList)) {
                break;
            }
            //将VIP用户的ID集合传给订单中心，计算出全年订单总金额大于1万的目标用户，并返回userIDList
            List<Long> targetUserIDList = orderClient.findGreaterThanAmount(userIDList, 1000000, 2023);
            //批量保存数据
            couponUserMapper.batchSave(targetUserIDList, couponID);
            //获取本批次中的最大用户ID，作为下个批次的起始ID传入
            startUserID = targetUserIDList.stream().collect(Collectors.summarizingLong(i -> i)).getMax();

        }
    }
```

然后，我们看一下订单中心里面，那个获取全年订单总金额大于 10000 元的用户数据的 SQL，也就是 `findGreaterThanAmount(userIDList, 1000000, 2023)` 方法中的 SQL 语句：

```SQL
SELECT user_id , SUM(amount) AS total_amount FROM ea_order 

WHERE  create_time > '2023-01-01' AND create_time < '2024-01-01' 
AND user_id IN(1234, 1235, 1236, 1237, ...) 

GROUP BY user_id  HAVING total_amount > 1000000;
```

其实，就是将传入的 100 个 user_id 进行 in 操作，并按照 user_id 进行分组，算出来其中大于 1000000 分（10000 元）的 user_id 并返回结果。

如上文所述，从订单中心返回的数据就会从 5000 条完整的订单记录，变成 50 个全年订单总金额大于 10000 元的单列 user_id 了，数据量减少为原来的 1/100 都不止，并且 user_id 本身也是一个区分度很高的索引字段。

另外，人券绑定操作也优化成 `couponUserMapper.batchSave(targetUserIDList, couponID)` 批量操作了，这样整个代码段已经没有性能瓶颈点了。

经过这波优化，目前优惠券下发时长从 30 小时优化至 3.5 小时。



## 集群并行优化

继续优化之前，我们先来了解一下分布式任务调度平台 —— `XXL-JOB`，它是跟 SpringTask 这种单机任务调度框架有所区别的。

XXL-JOB 具备开发迅速、学习简单、轻量级、易扩展等优点，支持动态修改任务状态、启动/停止任务，终止运行中任务，即时生效，且支持弹性扩容缩容，一旦有新执行器机器上线或者下线，下次调度时将会重新分配任务。

另外，XXL-JOB 的任务调度流程全异步化设计实现，如：异步调度、异步运行、异步回调等。


<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/66512ecd070749a9a16c30fe14270760~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=720&h=381&s=129536&e=png&b=bdd9ee" alt=""  /></p>


如上图所示，XXL-JOB 由两大部分组成，调度中心和执行器。

-   **调度中心**，负责管理调度信息，按照调度配置发出调度请求，自身不承担业务代码，支持集群部署。
-   **执行器**，负责接收调度请求并执行任务的业务逻辑，支持集群部署。

XXL-JOB 包含多种路由策略：第一个、最后一个、轮询、随机、一致性 HASH、最不经常使用、最近最久未使用、忙碌转移、故障转移、分片广播等。

这里着重介绍一下`分片广播`，任务路由策略选择 “分片广播” 情况下，一次任务调度将会广播触发集群中所有执行器执行一次任务，可根据分片参数（shardIndex）来开发分片任务。

如下图所示：

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/44d95009d7d44968ad2530c99f18497e~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=720&h=381&s=104480&e=png&b=fdfdfd" alt=""  /></p>


对应的代码 demo 如下：

```java
@XxlJob("broadcastJob")
public void broadcastJob() {
    int shardCount = XxlJobHelper.getShardTotal(); // 分片总数
    int shardIndex = XxlJobHelper.getShardIndex(); // 当前分片项

    // 执行任务逻辑
    for (int i = 1; i <= 全部任务ID; i++) {
        if (i % shardCount == shardIndex) {
            // 当前分片项需要执行的任务逻辑
            System.out.println("分片 " + shardIndex + "负责执行任务" + i);
        }
    }
}
```

XXL-JOB 的调用类型包括：Cron 表达式、固定速度、手动触发、API 调用触发等。我们在这个 case 中会用到的是，通过 RESTful API 触发调度任务。

接下来我们正式开始，通过 XXL-JOB 的分片广播模式来进行集群并行优化。

如下图所示，在优惠券下发的四个步骤中，除了第一步，其他三个步骤都是可以用“集群并行”的方式去优化的。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cdb68104007f4770bd6cebb75d5b9c28~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=720&h=376&s=100325&e=png&b=fefefe" alt=""  /></p>



XXL-JOB 的分片广播模式的解决方案如下：

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8680d3ea0e0f474fb834937ed6ceb310~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=720&h=400&s=124985&e=png&b=fefefe" alt=""  /></p>



于是，我们就可以在“创建优惠券”之后，通过 RESTful API 的方式，以分片广播模式去触发各个执行器来执行优惠券下发任务了。

接下来我们写一下代码 demo，如何通过 RESTful API 触发调度任务的代码就不写了，主要是写一下进行集群并行优化的代码。demo 如下：

```Java
@XxlJob("tenThousandAmountVIPJobHandler")
    public void tenThousandAmountVIPExecute() {
        //分片总数
        int shardCount = XxlJobHelper.getShardTotal();
        //当前分片项
        int shardIndex = XxlJobHelper.getShardIndex();

        int couponID = Integer.parseInt(XxlJobHelper.getJobParam());

        //偏移量，用来控制获取VIP用户的位置，类似于SQL语句中的offset，起始位置是0
        long startUserID = 0;

        for (int i = 0; i < shardCount; i++) {
            if(i == shardIndex){
                startUserID = i * 10000000 + 1;
            }
        }
        //结束位置
        long endUserID = startUserID + 10000000 - 1;

        while (true) {
            //批量获取VIP用户的ID集合，每次100条
            List<Long> userIDList = userClient.findVIPBySizeAndOffset(100, startUserID);

            //如果等于空，代表数据没有新的数据返回，则退出
            if (CollectionUtils.isEmpty(userIDList)) {
                break;
            }

            //将VIP用户的ID集合传给订单中心，计算出全年订单总金额大于1万的目标用户，并返回userIDList
            List<Long> targetUserIDList = orderClient.findGreaterThanAmount(userIDList, 1000000, 2023);

            //解析List
            targetUserIDList.stream().forEach(userID -> {
                if(userID <= endUserID ){
                    couponUserMapper.save(userID, couponID);
                }

            });

            //获取本批次中的最大用户ID，作为下个批次的起始ID传入
            startUserID = targetUserIDList.stream().collect(Collectors.summarizingLong(i -> i)).getMax();

            //如果大于等于endUserID，证明任务范围内的数据已经处理完成，则退出
            if(startUserID >= endUserID){
                break;
            }
        }
    }
```

最终，我们通过执行器集群中的 10 个节点并行执行的方式，将优惠券下发时长从 3.5 小时（210 分钟） 优化为它的 1/10，也就是约等于 20 分钟。




## 可量化结果

这个 case 我们是分为两个批次进行优化的。

- 批次一：通过`优先过滤优化 + 批量优化`后，将优惠券下发时长从 30 小时优化至 3.5 小时。

- 批次二：通过`集群并行`的方式，将优惠券下发时长从 3.5 小时优化至 20 分钟。



## 总结

这两个章节我们主要讲了三种优化策略：优先过滤优化、单次改批量优化和集群并行优化，这是三个非常有效的性能优化策略。

另外，本文还给大家普及了一下分布式任务调度平台 XXL-JOB，以及 XXL-JOB 中偏冷门小众的用法，路由策略中的分片广播模式和调用类型中的 API 调用触发。

最后需要说的是，我们在回答面试官性能优化的相关问题，一定要拿出非常 “自洽” 的性能量化结果指标，只有这样才会被面试官所信服。