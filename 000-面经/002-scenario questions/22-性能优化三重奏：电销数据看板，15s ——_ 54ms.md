本文我们继续来死磕性能，这次需要性能优化的场景与前两个迥然不同，是一个统计分析类的场景。

基于这个场景，我们会通过以下两种方式进行优化：并行计算方向中的`单机多线程并行计算`，以及预计算方向中的`全量预计算`。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fad1ca068cec4165937126365c293443~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=720&h=314&s=82924&e=png&b=fefbfb" alt=""  /></p>


下面我们就来一步一步地看下，是如何将该业务场景所对应的接口响应时间，从 15 秒优化至 54 毫秒的。



## 真实案例

### 业务场景 & 对应指标

某大型公司的经营分析报表系统，里面有一个包含了几十个指标的“销售数据看板”页面，主要是围绕着“销售金额”的数据进行多维聚合统计的，维度包括：年度、月度、地域、客户级别、客户销售明细等。此外，客户销售明细中还包括成本、毛利、毛利率等统计项。

如下图所示：


<p align=center><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0c6f2987887847a9bacc6cdec034521f~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1139&h=659&s=151861&e=png&b=f8f8f8" alt="image.png"  /></p>



这种统计分析类的场景，一般系统的 QPS 都不会高，基本上都是个位数。但目前该页面所对应接口的响应时间，大概在 15 秒左右，性能存在很大问题，用户体验很差。



### 性能问题的对应原因

之前“销售数据看板”页面，需要统计的字段并没有这么多，但随着产品经理的业务需求不断迭代，终于演变成了现在这个样子。

除此之外，由于公司的业务发展迅猛，年销售额已经从去年的 5 个亿，增加到了今年的 20 多个亿。而所对应的销售记录主表数据也从去年的全年 50 万条，增加到了今年的 200 多万条。

该“销售数据看板”页面的字段越来越多，数据量越来越大，也就意味着其处理性能越来越慢，已经由最初的两三秒钟打开该页面，渐渐变成了去年需要六七秒才能打开页面，而现在打开页面的时间竟然达到了惊人的 15 秒钟。这也导致了系统用户的操作体验极差，一时间怨声载道。

但据产品经理说，在他后续的产品需求中，仍然会往这个页面中加入更多具备参考价值的新指标。因此，对该页面进行性能优化已经是刻不容缓了。





### 思考和落地路径

如果大家看了“性能优化三重奏”的前两章，那首先想到的性能优化策略就是 —— 并行计算。

**并行计算**：其体现的思想是 “人多力量大，众人拾柴火焰高”，旨在通过将任务拆解后，以多路并行的方式，将任务执行的总时长进行缩短，以达到提升性能的目的。

那么，我们仍然可以用 CompletableFuture 的 allOf() 方法，来实现单机多线程并行计算（具体代码略过）。

如下图所示，销售数据报表的多路并行执行，应该取其执行路径中的最长耗时，也就是 “客户销售明细” 步骤的 5 秒执行时间。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d5e1d4c665024d74b0279fdba258764c~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=560&h=340&s=43368&e=png&b=fefefe" alt=""  /></p>



优化后，销售数据看板页面所对应的接口执行时长，已经从 15 秒优化到了 5 秒，性能一下子提升了不少。如果我们想继续优化，还可以将客户销售明细继续进行拆解，分为客户销售金额和成本两项。

因为后面的毛利和毛利率这两项，都是通过客户销售金额和成本进行简单计算得来的，并不耗费时间。

如下图所示：

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1faf1509a6374fd4ba77caca6c2d5b94~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=554&h=392&s=56699&e=png&b=fefefe" alt=""  /></p>



这样，优化后的销售数据看板页面所对应的接口执行时长，就变成了 3.5 秒。对于统计分析类的场景来说，3.5 秒的执行时长应该是个可以接受的结果了，但仍然留下隐患没有解决。

现在统计数据是 200 多万条，如果未来的一年增长到 500 多万，甚至超过 1000 万，接口执行时长又会增加很多，甚至会突破 10 秒大关。

这样的话，我们必须要使用其他的方案进行性能优化，首先想到的就是通过“预计算”的方式进行优化。

**预计算**：这是一种 “笨鸟先飞” 的思想，在用户请求到来之前，先将结果计算好并保存在缓存或数据库中。当用户触发请求的时候，直接返回准备好的结果，减少用户等待时间。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b6cc274e704a4fe8bb2b95ceed089399~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=654&h=406&s=85675&e=png&b=ffffff" alt=""  /></p>


预计算的优缺点非常分明，其优点是性能足够高。缺点是，可能数据结果为非实时数据，存在时延性，也可能是技术方案比较复杂。

预计算的另外需要考虑的点是：结果命中率和计算范围，也就是说，我们希望结果命中率越高越好，而计算范围越小越好。因为计算范围越大，计算的周期就越长，对硬件存储的消耗也就越大。

预计算又可以分为`全量预计算`和`存量预计算 + 增量即席计算`两种。

#### 全量预计算

上图中的流程就是基于全量预计算的。

这种方式代码实现简单，一条或几条复杂的大 SQL 就能搞定，但如果数据量特别庞大，可能会出现执行时间很长，甚至跑不出来结果的情况。

#### 存量预计算 + 增量即席计算

我们还是以“销售数据看板”为例，假设今天为 12 月 15 日，那么前三个季度的销售额已经是不可变的存量数据了，我们只需要预计算一次，并将它存储到 MySQL 或 Redis 中即可，不用每次跑任务都进行计算。

接下来我们再说说第四个季度，其实 12 月 14 日及以前的销售额也是不可变的存量数据，我们一样可以将它存储下来以作备用。

这时，当前端的请求发送过来，我们只需要即席计算 12 月 15 日的增量销售额数据，然后再跟 12 月 14 日及以前的存量销售额数据进行累加，即可得出实时的第四季度销售额数据。

另外一个问题是：在什么时间点进行存量数据累加？比较常见的做法是，每天的 0 点跑定时任务，把前一天的全天销售数据累加进之前存量数据中。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1682db1e3d544e348795542c8d7ffedd~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=652&h=396&s=29720&e=webp&b=fefefe" alt=""  /></p>



这种方式同时兼备高性能和实时性的优点，唯一的缺点就是技术方案相对复杂。
  

总之，“全量预计算”和“存量预计算 + 增量即席计算”，这两种预计算的策略，都非常适合于统计分析类场景。


在本文的 case 中，由于涉及的数据量级不算很大，且可以接受一定的时延性，因此我们选择的是方案较为简单的“全量预计算”进行实现的。

至于实现方式，找一个相对主流的、无论是单机的还是分布式的定时任务都可以实现，常用的有：XXL-JOB、Elastic-Job、SpringTask、ScheduledThreadPoolExecutor 等。

于是，我们便通过 XXL-JOB 分布式任务调度平台的故障转移模式，每三分钟执⾏⼀次各个维度销售汇总指标的任务，并将结果存储在 Redis 中，最终将“销售数据看板”的开表时间从 15 秒优化至 54 毫秒，这是一种以数据时延性换取性能的方案。

当用户请求到来的时候，直接返回 Redis 中已经预计算好的数据，不需要来一个用户请求就进行一次实时计算了。

### 可量化结果 & 答疑

1. 真的可以 54 毫秒就执行完成吗？

其实完全没有问题，这种销售指标我们可以用 Key Value 的形式存成一个大 Json 串，用户请求过来的时候直接返回结果就可以，不再需要进行任何耗时的操作了。

2. Redis 中如何进行存储？

我们每次通过 XXL-JOB 的执行器往 Redis 写入数据的时候，都是使用相同的 Key 直接覆盖以前的数据结果，使该 Key 下的数据永远都是最新的结果。

3. 为什么不使用 XXL-JOB 的分片广播模式呢？

很简单，因为没有必要。

我们的这个业务场景一共分为两个步骤，一个是通过 XXL-JOB 定时任务计算出结果并往 Redis 里面写数据，另一个是在用户发送请求的时候从 Redis 里读数据。

而前者不需要执行得太快，理论上只需要在任务执行的间隔期内把结果计算出来即可。况且，我们已经通过 CompletableFuture 的单机多线程并行处理进行兜底优化了，没必要继续增加复杂度。




## 总结

预计算方向是对统计分析类场景进行性能优化的最佳策略，而绝不是什么优化 SQL、加索引之类的方式，因为在绝对的数据量面前，这些都是弟弟。

我们在技术面试中应对面试官的时候也一样，一定要把性能优化方向跟面试官解释清楚。