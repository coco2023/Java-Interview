面试官：“如果你所负责的系统的 QPS（TPS）提升十倍或百倍，你要做哪些事情来应对？”

不得不说，从面试官的角度来看，这是一个非常聪明的技术问题。

当面试官抛出这个纯开放性的问题之后，他就完全可以以旁观者的姿态，静静地聆听着候选人对于该问题的解答。当面试官发现候选人解答过程中的漏洞后，便伺机提出更加刁钻的连续追问，最终将候选人问得哑口无言。

而从候选人的角度来看，这又是一个比较“坏”的技术问题。

因为绝大部分已经成熟的系统，无论是系统的用户访问量还是数据增量都非常固定，谁天天没事干想着 QPS （TPS） 十倍或百倍提升这些事情啊，这不是现代版的杞人忧天吗？

对于这个技术问题的解答，关键点在于其前后逻辑的缜密性和自洽性。



## 反面案例

我们先来看一下，回答该问题的反面案例。

面试官：“请你说一下，如果你所负责的系统的 QPS（TPS）提升十倍或百倍，你要做哪些措施来扛住高并发压力？”

候选人明显有些结巴：“这个。。。那我们需要先将应用服务器进行扩容，然后再引入 Redis 当缓存，最好连 Caffeine 这种本地缓存也一起用上。再有就是，MySQL 数据库也需要增加几个从库，以及把 ElasticSearch 也引入进来。”

面试官：“那你做了这些事情之后，系统就能扛住十倍或者百倍的 QPS （TPS） 吗？你是如何得出这个结论的？”

候选人：“这个也得需要进行压测，才能得出来具体的结论。”

面试官：“那你的做法就有问题了，为什么不是先进行压测，找到系统的瓶颈点之后，再有针对性地进行扩容或制定解决方案呢？”

候选人：“这个。。。。。。抱歉，我确实没太想清楚。”




## 解决步骤

下面我们来看下，该问题的正确解决步骤是怎样的。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/662ac33d2ebd4c688d901ce87900345e~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=714&h=245&s=33569&e=png&b=ffffff" alt=""  /></p>



### 1. 压力测试

其实道理很简单，既然系统的 QPS（TPS） 提升十倍或百倍了，那我们首先要做的事情，就是通过压力测试的方式去构建 QPS（TPS） 提升十倍或百倍的业务场景。

我认为最好的方案是，在系统的业务低峰期以真实流量回放、并递增加压的方式（1 倍、1.5 倍、2 倍、2.5 倍、3 倍等）在生产环境上进行压测，观察系统的瓶颈点在哪里。

该瓶颈点可能出在数据库服务器的 CPU 利用率、磁盘 IOPS、网络 IO 上，也可能出在数据库中的锁征用上，或是把应用服务器的 Tomcat / Jetty 的线程池打满了，又或是消息队列中的消息积压了，等等。



### 2. 代码优化

当我们找出系统中的瓶颈点后，就可以顺藤摸瓜地跟进到具体的业务代码实现上。

**示例一：**

应用服务器的 Tomcat / Jetty 的线程池打满了，用户请求已经开始积压阻塞的时候，我们可以通过 Skywalking 链路追踪工具进行查看，是否出现系统中某接口，以及某接口中的某个链路步骤（如：下游系统调用、数据库操作、接口自身业务逻辑）出现了耗时较多的情况。

定位到该问题的具体实现代码或 SQL 语句后，则开始进行性能优化。

**示例二：**

当发现数据库服务器的 CPU 利用率达到了 100% 时，我们可以查询是否有特别消耗数据库硬件资源的慢查 SQL，若有的话将其摘取出来，通过 Explain 关键字来查看该慢查 SQL 所对应的执行计划，分析过后通过添加索引、重写 SQL、FORCE INDEX 干涉等方式进行优化。

**示例三：**

当发现消息队列的消息积压严重，消费者的处理速度跟不上生产者的创建速度时，可以通过 SQL 语句单次改批量、逻辑校验串行改并行、高频访问的数据预热、代码逻辑简化及复用等方式，来提升消费者的消息处理吞吐量。

代码优化过后，我们重新回到步骤 1 ，继续进行系统的压力测试工作，看看系统现在是否能承载的峰值 QPS （TPS）达到目标值 1.3 倍以上。

> btw：之所以需要达到目标值的 1.3 倍以上，主要是为了让系统留有余量，这样能够容纳一些预估偏差和数据增量带来的影响。


### 3. 硬件扩容

当我们把系统中存在问题的代码全部优化完毕，继续进行压测却依然达不到目标 QPS 时 ，就可以考虑通过硬件扩容的方式来进行解决了，因为此时我们已经别无他法了。

当然，硬件扩容有分为两种：`纯硬件扩容`和`技术方案改造 + 硬件扩容`。

**纯硬件扩容**

举个例子来说，随着业务的迅猛发展，我们的数据库服务器已经不能扛住系统中所有的 SQL 操作时，我们可以创建两个数据库从库，并将对时延性要求较低的业务场景的对应 SQL 迁移过来，以此分担数据库主库的压力。

**技术方案改造 + 硬件扩容**

最贴切的例子就是，我们的数据库主库中的业务主表进行分库分表，以此解决  MySQL 数据库在海量数据的存储和并发读写瓶颈问题。这时，我们需要在业务代码中来解决分库分表方案所带来的各种问题（数据时延性、分库分表路由、结果数据聚合等）。

硬件扩容完成后，我们重新回到步骤 1 ，继续进行系统的压力测试工作，探测本次的扩容操作是否到位。若仍然无法支撑目标 QPS 或 TPS，则继续进行扩容，直到系统所能承载的峰值 QPS （TPS）达到目标值 1.3 倍以上为止。


### 4. 限流兜底

这是最后一步，也是系统的最终`兜底策略`，如果系统之前没有引入限流策略的话，这次一定要加上。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6fd97d52bad441cd8a936d01bf1fd656~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=495&h=381&s=52861&e=png&b=fefefe" alt=""  width="70%"/></p>


我们虽然一直在生产环境上进行压测，但当真正十倍或百倍级 QPS（TPS）到来之前，谁也没有真正的把握一定能扛住这波流量。

我在前文中写过，限流的关键点，从来不在工具上，而在于其阈值设置和多级布控上，我们这里着重讲讲阈值设置。

最终的系统限流阈值设定，应该是大于等于目标的 QPS（TPS），并小于系统所能承载的峰值 QPS（TPS）。


<p align=center><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6a0e34c9435b4c6eb6df79102861507b~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=498&h=344&s=17857&e=png&b=ffffff" alt="image.png"  /></p>



## 总结

在本文中，我们纠正一个常见的技术面试题的错误回答方式，并着重讲解了如何用正确方式去实战落地，以及解答面试官的技术问题。

该场景下的正确方式为：`压力测试 ——> 代码优化 ——> 硬件扩容 ——> 限流兜底`，旨在逻辑自洽缜密地贯彻 “**先度量，再调优，后扩容，终兜底**” 的方法论。