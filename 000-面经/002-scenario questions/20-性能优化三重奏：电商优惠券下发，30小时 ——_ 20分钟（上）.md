在本文中，我们继续来讲 “电商优惠券下发” 场景的性能优化，以及会讲到 “并行计算” 方向中的 “集群并行计算” 策略，和 “其他算法优化” 中的 “优先过滤优化” 和 “批量优化”。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f8f85a6787de41ecbe5a399b80115a4b~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=720&h=314&s=82924&e=png&b=fefbfb" alt=""  /></p>


下面我们就来一步一步地看下，是如何将该业务场景的执行时长从 30 个小时优化至 20 分钟的。




## 真实案例

### 业务场景 & 对应指标

我先来跟大家介绍一下优惠券相关的内容。

优惠券是一种常见的营销推广手段，可针对于不同用户人群，制定不同的精准营销策略，如：拉新、促活、提升客单价、复购等。

优惠券的发放主体为平台和店铺两种，使用范围包括：单品、店铺、品牌、品类、全场等， 获取方式有：用户领取、用户购买、系统自动触发、系统手动发放。

这次我们讲的是平台的运营人员，以系统手动发放优惠券的方式，将其发送给年订单消费金额在一万+ 的 VIP 用户。券类型为满 1000 减 200 的满减券。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5b90771a208943e6b211d7d4534cc9fa~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=373&h=410&s=43550&e=png&b=fdfdfd" alt=""  /></p>



在定时任务发放优惠券的过程中，我们发现其执行得非常慢，给一千万用户发放优惠券需要整整 20 个小时，运营人员希望研发团队能够对优惠券的发放速度进行优化。



### 性能问题的对应原因

我们拆解一下优惠券下发的整体步骤，便于大家进行理解。下图为点击“优惠券发放”按钮后的请求流转过程：

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ba2a24185a654f2384aea4c09a339364~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=720&h=373&s=111629&e=png&b=fefefe" alt=""  /></p>



我们的系统也是按照微服务架构进行设计的，本次优惠券下发会涉及到三个系统，包括：优惠券系统、用户中心和订单中心，每个系统都有它独立的库表。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b48ab49f8a9d4a218ed2529ee3dfe4db~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=720&h=377&s=107868&e=png&b=fefefe" alt=""  /></p>


其具体业务步骤如下：

1. 在优惠券系统中创建满 1000 减 200 的优惠券，以备后续发放使用。
2. 优惠券系统分批从用户中心获取 VIP 用户的用户 ID，每批为 100 个。
3. 优惠券系统将这 100 个 VIP 用户 ID 传入订单中心，获取 VIP 用户的全年订单记录。
4. 优惠券系统计算出全年订单总金额大于 1 万的用户，然后进行优惠券下发操作，也就是将人券进行绑定。
5. 重复步骤 2、3、4，直到从用户中心获取完 VIP 用户为止。



对应的代码逻辑如下：

```java
public void distributeCoupons(Coupon coupon, int userGroupID) {

        //插入优惠券，获取优惠券ID
        couponMapper.save(coupon);
        int couponID = coupon.getId();
        //偏移量，用来控制获取VIP用户的位置，类似于SQL语句中的offset，起始位置是0
        long startUserID = 0;
        while (true) {
            //从用户中心批量获取VIP用户的ID集合，每次100条
            List<Long> userIDList = userClient.findVIPBySizeAndOffset(100, startUserID);
            //如果等于空，代表数据没有新的数据返回，则退出
            if (CollectionUtils.isEmpty(userIDList)) {
                break;
            }
            //将VIP用户的ID集合传给订单中心，获取用户ID和全年所有订单的Map
            Map<Long, List<Order>> userOrderMap = orderClient.findByIDList(userIDList, 2023);
            userOrderMap.entrySet().stream().forEach(entry -> {
                long userID = entry.getKey();
                //将VIP用户的订单金额进行累加，算出总值
                long totalAmount = entry.getValue().stream().collect(Collectors.summingLong(Order::getAmount));
                //判断总值大于1000000分（10000元）
                if (totalAmount > 1000000) {
                    //发放优惠券，将用户ID和优惠券ID进行绑定
                    couponUserMapper.save(userID, couponID);
                }
            });
            //获取本批次中的最大用户ID，作为下个批次的起始ID传入
            startUserID = userOrderMap.keySet().stream().collect(Collectors.summarizingLong(i -> i)).getMax();
        }
    }
```

接下来我们再从数据的角度来解释一下：

目前系统中总用户数是 1 亿，而 VIP 用户数是 2000 万，占比为 20%。

而这 2000 万 VIP 用户中，人均订单 50 个，这也就意味着，如果每批给订单中心传入 100 个 VIP 用户 ID 的话，大约会从订单中心获取大约 5000 个订单记录。

另外，全年订单总金额大于 1 万的 VIP 用户数是 1000 万，占 VIP 用户数的 50%，总用户数的 10%。

由此得出下图的结论：

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c361f1f716d347d5a34827475dd73fc9~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=720&h=389&s=129619&e=png&b=fdfdfd" alt=""  /></p>



这里再解释一下，为什么一个批次的操作会消耗 500ms，以及从订单中心获取 VIP 用户的全年订单记录，会占总执行时长（500ms）的 85%。

原因在于，这 5000 个订单需要通过 SQL 语句从数据库磁盘中读取出来，然后通过网络发送给订单中心服务，加载进订单中心服务的 JVM，再通过网络发送给优惠券系统服务，加载进优惠券系统服务的 JVM，这就是 5000 个订单的整体流转路径。

然后我们通过公式可以得出：50 个优惠券 / 500 毫秒 * 2 * 3600 秒 * 30 小时 = 1080 万

这也就是电商千万量级优惠券下发，需要足足 30 个小时的整体原因分析。




### 思考和落地路径

如上文所述，从订单中心获取 VIP 用户的全年订单记录，这一个步骤会占总执行时长（500ms）的 85%。

擒贼先擒王，如果我们想要让优惠券下发场景的性能大幅提升的话，必须要对这个步骤动刀子。

在动刀子之前，我们先讲两个性能优化的策略：“优先过滤优化” 和 “单次改批量优化”。



#### 1. 优先过滤优化

很多系统性能问题，都是参与计算的数据量过于庞大造成的，而洞察庞大的数据量中的无用数据，并进行先行过滤，在某些场景下是可以大幅提升性能的。

而过滤方式包括两种：`SQL 过滤`和`服务过滤`。

SQL 过滤，假设如下场景，某统计局需要统计出北京和上海居民的平均收入。

反例的实现方式为，从 people 表中读出所有人民收入数据后，按照城市对其进行分组并求出平均收入，再通过 having 过滤出北京和上海人民的平均收入。

```
select city, avg（salary） from people group by city having city ='beijing' or city = 'shanghai';
```

而正解的实现方式为，从 people 表中读出人民收入数据后，把北京和上海人民的收入数据过滤出来，再分组求出北京和上海人民的平均收入。

```
select city, avg（salary） from people where city ='beijing' or city = 'shanghai'  group by city;
```

其差别在于，分组和求平均值的数据量级大小，不同的数据量级的 SQL 执行时间是完全不一样的，正解 SQL 的执行性能明显要高出很多。

服务过滤还是比较好理解的，我们尽量在下游服务 B 中将无用的数据过滤掉，这样服务 B 将数据回传给服务 A，服务 A 再回传给用户端时，其网络和 JVM 的资源占用都会小很多，从而提升了系统性能。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c36f3bbd280c4382878f979917b49d7b~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=720&h=387&s=78495&e=png&b=fefefe" alt=""  /></p>



#### 2. 单次改批量优化

如下图所示，单次改批量提升性能的原因是，无论是网络传输、SQL 解析、生成 SQL 执行计划，以及数据库的磁盘 IO，都从两次变成了一次，唯独业务数据量是相同的而已，这样性能一定是提升的。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7628d353361d4516a117ce589af9a972~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=741&h=378&s=36226&e=png&b=fefefe" alt=""  /></p>



讲完了理论知识，我们再回头看下，如何优化 “从订单中心获取 VIP 用户的全年订单记录” 这个步骤。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fbf62a07bbbc49c9958adfcfdb2ced30~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=720&h=377&s=107868&e=png&b=fefefe" alt=""  /></p>



其实仔细想想，我们需要的不是 “VIP 用户的全年订单记录”，而是 “全年订单总金额大于 1 万的用户数据”，对吧？

这样返回的数据就会从 5000 条完整的订单记录，变成 50 个全年订单总金额大于 1 万的单列用户 ID 了，数据量减少为原来的 1/100 都不止，这样性能就可以提升上来了。

如下图所示：


<p align=center><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8572ccd2e9ef459f98a5f27390b9a4c0~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=800&h=445&s=82802&e=png&b=fefefe" alt="image.png"  /></p>




## 总结

鉴于篇幅原因，本文我们介绍了优惠券下发的现状分析，以及对应的性能优化策略：“优先过滤优化”和“单次改批量优化”。

下文中，我们会将这两个性能优化策略进行落地实现，以及介绍并落地其他优化策略，最终将千万量级优惠券下发执行时长优化至 20 分钟。